{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab90f7f3-427c-452b-bd48-200ddc34b8cc",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Data preparation and training\n",
    "\n",
    "These scripts are designed to prepare data for YOLO training.\n",
    "\n",
    "The training folder must contain three elements :\n",
    "- a 'labels' folder: in which annotation files are stored,\n",
    "- an 'images' folder: in which image files are stored,\n",
    "- a 'labels.txt' file: containing annotation data in YOLO format: \n",
    "    - '0': 'class 0',/n '1': 'class 1',/n etc.\n",
    "    \n",
    "\n",
    "The *Image transformation* section is designed to double the training dataset by starting from annotated image data, using image warping: images and annotations are deformed according to the same transformation matrix.\n",
    "\n",
    "For each image and annotation file, a new file is generated with the following characteristics:\n",
    "\n",
    "+ A new image with a modified perspective: a new image is created by applying a perspective transformation matrix to the original image.\n",
    "+ A new text file containing annotations adjusted according to the transformation applied to the image: each annotation associated with the original image is also transformed using the same perspective transformation matrix. The new annotation coordinates are then saved in a new text file.\n",
    "\n",
    "The data generated by perspective transformations are labelled \"filename_TP\".\n",
    "\n",
    "All these scripts are designed to process image and text data with the same name (except for the extension) contained in the 'labels' and 'images' folders.\n",
    "\n",
    "You can use unannotated images for the training session. In this case you can create an empty file or no file, the result will be the same: https://github.com/ultralytics/yolov5/discussions/7148#discussioncomment-2440612 \n",
    "\n",
    "**Notice concerning use** \n",
    "Any use, even partial, of the content of this notebook must be accompanied by an appropriate citation.\n",
    "\n",
    "&copy; 2023 Marion Charpier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ee6c24-9f4b-41b4-b4a3-82bc16f5004a",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Environment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6db34875-9c39-487a-a0a3-89508534379c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import shutil\n",
    "import random\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "import cv2\n",
    "import yaml\n",
    "import torch\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys\n",
    "sys.path.append(str(Path.cwd().parent / 'modules'))\n",
    "\n",
    "from folders_path import get_data_folder\n",
    "from device_function import which_device\n",
    "from class_names_functions import get_labels\n",
    "from corners_functions import get_corners, from_corners_to_relative\n",
    "from transform_coordinates_functions import from_relative_coordinates_to_absolute"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d11982cc-7b26-4d37-830c-0653252385a5",
   "metadata": {},
   "source": [
    "## Cleaning annotation files (.txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "097352de-5bcb-4f4e-a67c-3c9acbce10c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_comma(project_folder:str) -> None:\n",
    "    \"\"\"\n",
    "    This function removes any commas that may appear in the annotation `.txt` files within the specified training folder.\n",
    "    This is particularly useful when annotation files are generated or modified from CSV files, \n",
    "    as commas can accidentally be included and cause issues during model training.\n",
    "\n",
    "    :param project_folder: \n",
    "        - Type: str\n",
    "        - Description: The absolute path to the folder named after the project.\n",
    "\n",
    "    :return: \n",
    "        - Type: None\n",
    "        - Description: This function modifies `.txt` files in place, removing any commas that are found.\n",
    "\n",
    "    This function ensures that annotation files are formatted correctly, preventing errors during the training process.\n",
    "    \"\"\"\n",
    "    data_folder = Path(get_data_folder(project_folder))\n",
    "    labels_folder = data_folder / 'labels'\n",
    "    \n",
    "    for file in labels_folder.iterdir():\n",
    "        if file.is_file() and file.suffix.lower() == '.txt':       \n",
    "            # Read the file content\n",
    "            with open(file, 'r') as f:\n",
    "                content = f.read()\n",
    "            # Remove commas\n",
    "            content_without_comma = content.replace(',', '')\n",
    "            \n",
    "            # Write the modified content in the file\n",
    "            with open(file, 'w') as file:\n",
    "                file.write(content_without_comma)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e054e7d-0e53-42d1-87b4-5025a7b0195d",
   "metadata": {},
   "source": [
    "## Increase dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cc58d24-d832-4a5b-bfdf-1354a51f13a1",
   "metadata": {},
   "source": [
    "### Image transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7670edd-ee9c-4493-a5b9-03d31e06fdb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perspective_transformation(img_file:str) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Applies a random perspective transformation to the input image and saves the result.\n",
    "\n",
    "    The function randomly adjusts the dimensions of the image to simulate a different viewing angle,\n",
    "    which is useful for data augmentation in machine learning workflows. The transformed image is\n",
    "    saved with the same name as the original, with '_PT' appended before the file extension.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    img_file : str\n",
    "        Absolute path to the image file to be transformed.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    numpy.ndarray\n",
    "        The 3x3 perspective transformation matrix (homography) used to warp the original image.\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    - The transformation randomly resizes the width and height to 30–80% of the original dimensions.\n",
    "    - The output image is saved in the same directory as the input.\n",
    "    - Useful for generating training data with varied viewpoints.\n",
    "    \"\"\"\n",
    "\n",
    "    # Open image and get dimensions\n",
    "    img = cv2.imread(img_file)\n",
    "    rows, cols = img.shape[:2]\n",
    "\n",
    "    # Define the points of origin for the perspective transformation.\n",
    "    # These points form a quadrilateral covering the entire original image.\n",
    "    pts1 = np.float32([[0, 0], [cols, 0], [cols, rows], [0, rows]])\n",
    "\n",
    "    # Generate a new random width and height for the transformed image, between 30% and 80% of the original width.\n",
    "    new_width = random.randint(int(cols*0.3), int(cols*0.8))\n",
    "    new_height = random.randint(int(rows*0.3), int(rows*0.8))\n",
    "\n",
    "    # Define the new points for the perspective transformation\n",
    "    pts2 = np.float32([[0, 0], [new_width, 0], [new_width, new_height], [0, new_height]])\n",
    "\n",
    "    # Calculate the perspective transformation matrix\n",
    "    M = cv2.getPerspectiveTransform(pts1, pts2)\n",
    "\n",
    "    # Apply the perspective transformation to the original image.\n",
    "    dst = cv2.warpPerspective(img, M, (new_width, new_height))\n",
    "\n",
    "    # Save the transformed image in the output folder\n",
    "    img_path = Path(img_file)\n",
    "    new_filename = f\"{img_path.stem}_PT{img_path.suffix}\"\n",
    "    transformed_img_path = img_path.with_name(new_filename)\n",
    "\n",
    "    cv2.imwrite(transformed_img_path, dst)\n",
    "\n",
    "    return M"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34eae5cb-d4e4-437c-90ac-d30ce4f24ac8",
   "metadata": {},
   "source": [
    "### Annotations transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ee1f015-ebb0-40fe-b6d0-a70645e0d751",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perspective_transformation_annotation(ann_file:str, img_file:str, M:np.ndarray) -> list:\n",
    "    \"\"\" \n",
    "    This function applies a perspective transformation matrix to the bounding box annotations of an image \n",
    "    and saves the new transformed annotations in a separate file. The transformed annotations correspond to\n",
    "    the modified perspective and dimensions of the image after applying the perspective transformation.\n",
    "\n",
    "    :param ann_file: \n",
    "        - Type: str\n",
    "        - Description: The absolute path to the annotation file (`.txt`) associated with the image. \n",
    "                       The file should contain bounding box annotations in YOLO format \n",
    "                       (label, x_center, y_center, width, height).\n",
    "\n",
    "    :param img_file: \n",
    "        - Type: str\n",
    "        - Description: The absolute path to the original image file. This is used to retrieve \n",
    "                       the original image dimensions and the dimensions of the transformed image.\n",
    "\n",
    "    :param M: \n",
    "        - Type: numpy.ndarray\n",
    "        - Description: The transformation matrix used for perspective transformation. This matrix \n",
    "                       is used to transform the bounding box coordinates to match the new image perspective.\n",
    "\n",
    "    :return: \n",
    "        - Type: list of tuples\n",
    "        - Description: Returns a list of transformed bounding box annotations. Each tuple contains \n",
    "                       the label and new relative coordinates (x_center, y_center, width, height) \n",
    "                       after applying the perspective transformation.\n",
    "\n",
    "    The function ensures that the bounding box annotations remain consistent with the perspective changes applied to the image,\n",
    "    which is essential for maintaining annotation accuracy after transformations.\n",
    "    \"\"\"\n",
    "\n",
    "    img_height, img_width = cv2.imread(img_file).shape[:2]\n",
    "    img_path = Path(img_file)\n",
    "    new_filename = f\"{img_path.stem}_PT{img_path.suffix}\"\n",
    "    transformed_img_path = img_path.with_name(new_filename)\n",
    "    TP_img_height, TP_img_width = cv2.imread(str(transformed_img_path)).shape[:2]\n",
    "    \n",
    "    # print(f\"Origal size: {img_height}, {img_width}\\nNew size: {TP_img_height}, {TP_img_width}\")\n",
    "\n",
    "    # Initialising a list to store the new bounding box coordinates \n",
    "    bb_coordinates = []\n",
    "\n",
    "    with open(ann_file, 'r') as annotations:\n",
    "        for line in annotations:\n",
    "            if not line.strip():\n",
    "                continue #skip empty lines\n",
    "\n",
    "            # Extraire les coordonnées de l'annotation\n",
    "            label, x_center, y_center, width, height = line.strip().split()\n",
    "            \n",
    "            #print(type(label), type(x_center), type(y_center), type(width), type(height))\n",
    "\n",
    "            # Convertir les coordonnées relatives en coordonnées absolues\n",
    "            corners = get_corners(x_center, y_center, width, height, img_width, img_height)\n",
    "\n",
    "            # Appliquer la transformation aux coins de la boîte d'annotation\n",
    "            corners = np.array(corners, dtype=np.float32).reshape(-1, 1, 2)\n",
    "            transformed_corners = cv2.perspectiveTransform(corners, M).reshape(-1, 2)\n",
    "\n",
    "            # Calculer les nouvelles coordonnées relatives\n",
    "            new_upper_left = transformed_corners[0]\n",
    "            new_bottom_right = transformed_corners[2]\n",
    "\n",
    "            #print(f'new_upper_left = {new_upper_left}, new_bottom_right = {new_bottom_right}')\n",
    "\n",
    "            # Transformer les nouvelles coordonnés en relatives\n",
    "            transformed_x_center, transformed_y_center, transformed_width, transformed_height = from_corners_to_relative(\n",
    "                new_upper_left, new_bottom_right, TP_img_width, TP_img_height)\n",
    "\n",
    "            bb_coordinates.append((label, transformed_x_center, transformed_y_center, transformed_width, transformed_height))\n",
    "    \n",
    "    annotations_path = Path(ann_file)\n",
    "    new_annotations_filename = f\"{annotations_path.stem}_PT{annotations_path.suffix}\"\n",
    "    new_annotation_path = annotations_path.with_name(new_annotations_filename)\n",
    "\n",
    "    with open(new_annotation_path, 'w') as transformed_annotations:\n",
    "        for bb in bb_coordinates:\n",
    "            label, x, y, w, h = bb\n",
    "            transformed_annotations.write(f\"{int(label)} {x:.6f} {y:.6f} {w:.6f} {h:.6f}\\n\")\n",
    "\n",
    "\n",
    "    return bb_coordinates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b31504-30e0-408a-b03b-986151135bd6",
   "metadata": {},
   "source": [
    "### Generate transformed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a765f94d-db8d-4a8a-86b4-a5671ea90072",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_transformed_data(project_folder:str) -> None:\n",
    "    \"\"\"\n",
    "    This function generates a set of transformed images and their corresponding annotations by applying \n",
    "    perspective transformations to each image and adjusting the bounding box annotations accordingly. \n",
    "    The new images and annotations are saved in the appropriate folders within the specified training folder.\n",
    "\n",
    "    :param project_folder: \n",
    "        - Type: str\n",
    "        - Description: The absolute path to the folder named after the project.\n",
    "\n",
    "    :return: \n",
    "        - Type: None\n",
    "        - Description: This function does not return a value. It generates transformed images and annotation files \n",
    "                       in place, saving them in the same subdirectories with modified filenames.\n",
    "\n",
    "    This function automates the data augmentation process by generating new variations of the dataset, \n",
    "    which can be used to enhance model robustness during training.\n",
    "    \"\"\"\n",
    "    \n",
    "    print('Image tranformation has started..')\n",
    "    \n",
    "    data_folder = Path(get_data_folder(project_folder))\n",
    "    labels_folder = data_folder / 'labels'\n",
    "    img_folder = data_folder / 'images'\n",
    "\n",
    "    img_exts = {\".jpg\", \".jpeg\", \".png\", \".tiff\"}\n",
    "    images = [img for img in img_folder.iterdir() if img.suffix.lower() in img_exts]\n",
    "\n",
    "    for img_file in images:\n",
    "        img_name = img_file.stem\n",
    "        ann_file = labels_folder / f\"{img_name}.txt\"\n",
    "        \n",
    "        if ann_file.exists():\n",
    "            try:\n",
    "                M = perspective_transformation(str(img_file))\n",
    "                perspective_transformation_annotation(str(ann_file), str(img_file), M)\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {img_file.name}: {e}\")\n",
    "\n",
    "    print(f'New images stored in {img_folder}\\nNew annotations stored in {labels_folder}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c8d8581-a974-496c-9c1b-6eee1f15dd38",
   "metadata": {},
   "source": [
    "## Create the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c1e51a4-c1dc-4f16-9eb7-d5744872c7bc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_training_dataset(project_folder:str, pretrained_model:str, preexisting_distribution:bool) -> None:\n",
    "    \"\"\"\n",
    "    Prepares training and validation datasets from a directory of images and labels.\n",
    "    Generates:\n",
    "    1. traindata.txt – 80% of images\n",
    "    2. valdata.txt – 20% of images\n",
    "    3. training_dataset.txt – all images\n",
    "\n",
    "    If a pre-existing split is provided, it's reused. Otherwise, a new random split is created.\n",
    "    Images and labels are copied into organized folders for training and validation.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    :param project_folder: \n",
    "        - Type: str\n",
    "        - Description: The absolute path to the folder named after the project.\n",
    "\n",
    "    :param pretrained_model: \n",
    "        - Type: str\n",
    "        - Description: The absolute path to the folder containing the pre-trained model data. \n",
    "                       This parameter is currently unused in the function but may be required for future enhancements.\n",
    "\n",
    "    :param preexisting_distribution: \n",
    "        - Type: bool\n",
    "        - Description: If `preexisting_distribution` is True, the function reuses a previous train/val split from \n",
    "                        the `pretrained_model` folder. Otherwise, it creates a new random split.\n",
    "\n",
    "\n",
    "    :return: \n",
    "        - Type: None\n",
    "        - Description: This function does not return a value. It creates and saves the text files \n",
    "                       `traindata.txt`, `valdata.txt`, and `training_dataset.txt` and organizes the images \n",
    "                       and labels into separate subdirectories for training and validation.\n",
    "\n",
    "    This function ensures that the training and validation data are correctly organized and ready for model training.\n",
    "    \"\"\"\n",
    "    \n",
    "    data_folder = Path(get_data_folder(project_folder))\n",
    "    project_folder = Path(project_folder)\n",
    "    project_name = project_folder.name\n",
    "\n",
    "    img_folder = data_folder / 'images'\n",
    "    img_train_folder = data_folder.parent / 'datasets' / project_name / 'images' / 'train'\n",
    "    img_val_folder = data_folder.parent / 'datasets' / project_name / 'images' / 'val'\n",
    "\n",
    "    labels_folder = data_folder / 'labels'\n",
    "    labels_train_folder = data_folder.parent / 'datasets' / project_name / 'labels' / 'train'\n",
    "    labels_val_folder = data_folder.parent / 'datasets' / project_name / 'labels' / 'val'\n",
    "    \n",
    "    data_stat_folder = data_folder / 'dataset_statistics'\n",
    "    data_stat_folder.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    train_data = data_stat_folder / 'traindata.txt'\n",
    "    val_data = data_stat_folder / 'valdata.txt'\n",
    "    training_dataset = data_stat_folder / 'training_dataset.txt'\n",
    "\n",
    "    \n",
    "    img_exts = {\".jpg\", \".jpeg\", \".png\", \".tiff\"}\n",
    "\n",
    "    if preexisting_distribution:\n",
    "        if pretrained_model:\n",
    "            print(f'Use pre-existing files from {pretrained_model}.')\n",
    "            previous_distribution = Path(pretrained_model) / 'dataset_statistics'\n",
    "            if not previous_distribution.exists():\n",
    "                raise FileNotFoundError(f\"No dataset_statistics found in {pretrained_model}\")\n",
    "            shutil.copytree(previous_distribution, data_stat_folder, dirs_exist_ok=True)\n",
    "            # TODO: Copy yaml file\n",
    "\n",
    "        else:\n",
    "            pretrained_model = str(input(\"Please indicate the path to the pre-trained model folder: \"))\n",
    "            if not isinstance(pretrained_model, str):\n",
    "                raise TypeError(f\"The pre-trained model folder path must be a string, not {type(pretrained_model)}\")\n",
    "\n",
    "    else:\n",
    "        # Get a list of the images\n",
    "        image_files = [img for img in img_folder.iterdir() if img.suffix.lower() in img_exts]\n",
    "        if not image_files:\n",
    "            raise ValueError(f\"No images found in {img_folder}. Please check your dataset.\")\n",
    "\n",
    "        # Shuffle file names randomly\n",
    "        random.shuffle(image_files)\n",
    "\n",
    "\n",
    "        # TODO: Add sklearn stratified split here for balanced class distribution\n",
    "\n",
    "        # Calcul le nombre d'images pour chaque ensemble\n",
    "        num_images = len(image_files)\n",
    "        num_train = int(num_images * 0.8)\n",
    "        num_val = int(num_images - num_train)\n",
    "\n",
    "        # Divide file names into two sets : one for the training, one for the validation\n",
    "        train_files = image_files[:num_train]\n",
    "        print(f\"{len(train_files)} images assigned to training.\")\n",
    "        val_files = image_files[num_train:num_train+num_val]\n",
    "        print(f\"{len(val_files)} images assigned to validation.\")\n",
    "        \n",
    "\n",
    "        # Create a file with the list for the train data\n",
    "        with open(train_data, 'w') as f:\n",
    "            for image_file in train_files:\n",
    "                f.write(str(image_file) + \"\\n\")\n",
    "        print(f\"File created: {train_data}\")\n",
    "\n",
    "        # Create a file with the list for valdidation data\n",
    "        with open(val_data, 'w') as f:\n",
    "            for image_file in val_files:\n",
    "                f.write(str(image_file) + \"\\n\")\n",
    "        print(f\"File created: {val_data}\")\n",
    "\n",
    "\n",
    "        # Create a file with all the dataset\n",
    "        with open(training_dataset, 'w') as f:\n",
    "            for image_file in image_files:\n",
    "                    f.write(str(image_file) + \"\\n\")\n",
    "            print(f\"File created: {training_dataset}\")\n",
    "    \n",
    "\n",
    "    # Split images and txt files into folders from a .txt file\n",
    "    split_data_for_training(str(train_data), \n",
    "                            str(labels_folder),\n",
    "                            str(img_train_folder),\n",
    "                            str(labels_train_folder))\n",
    "    \n",
    "    split_data_for_training(str(val_data),\n",
    "                            str(labels_folder),\n",
    "                            str(img_val_folder),\n",
    "                            str(labels_val_folder))\n",
    "    \n",
    "    # Create the yaml file\n",
    "    write_yaml_file(project_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f650486-2ca6-4a0e-94b7-a9a31b0508d1",
   "metadata": {},
   "source": [
    "## Split the data for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b0b1d63-f392-4cca-ac3d-bb54184a9c91",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def split_data_for_training(img_list:str, labels_folder:str, output_img_folder:str, output_labels_folder:str) -> None:\n",
    "    \"\"\"\n",
    "    Organizes images and annotation files into the appropriate YOLOv8 train/val subdirectories.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    img_list : str\n",
    "        Path to a `.txt` file containing absolute paths to image files (one per line).\n",
    "\n",
    "    labels_folder : str\n",
    "        Path to the folder containing corresponding `.txt` YOLO annotation files.\n",
    "\n",
    "    output_img_folder : str\n",
    "        Destination folder where the images will be moved (e.g., images/train or images/val).\n",
    "\n",
    "    output_labels_folder : str\n",
    "        Destination folder where the annotation `.txt` files will be moved (e.g., labels/train or labels/val).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "        Files are moved into the specified YOLO directory structure.\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    # Create the output folder if it does not already exist\n",
    "    output_img_folder = Path(output_img_folder)\n",
    "    output_img_folder.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    output_labels_folder = Path(output_labels_folder)\n",
    "    output_labels_folder.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Open the text file containing the image paths\n",
    "    with open(img_list, \"r\") as f:\n",
    "        # Browse through each line of the file\n",
    "        for line in f:\n",
    "            # Get the image path and text file name\n",
    "            image_path = Path(line.strip())\n",
    "            image_name = image_path.stem\n",
    "\n",
    "            txt_file = Path(labels_folder) / f\"{image_name}.txt\"\n",
    "\n",
    "            try:\n",
    "                # Copy image to output folder\n",
    "                shutil.move(str(image_path), str(Path(output_img_folder) / image_path.name))\n",
    "            except FileNotFoundError:\n",
    "                print(f\"Image file {image_path} not found.\")\n",
    "        \n",
    "            # Copy text file to output folder\n",
    "            try:\n",
    "                shutil.move(str(txt_file), str(Path(output_labels_folder) / txt_file.name))\n",
    "\n",
    "            except FileNotFoundError:\n",
    "                print(f'Text file {txt_file} does not exist')\n",
    "    print(f'Image files move in {output_img_folder}')\n",
    "    print(f'Text files move in {output_labels_folder}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7257e4d-d6ad-443d-9ff9-9587eb34c299",
   "metadata": {},
   "source": [
    "## Create the .yaml file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f09c1055-68d4-4cdb-bd74-4c6006d07056",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def write_yaml_file(project_folder:str) -> None:\n",
    "    \"\"\"\n",
    "    Creates a `.yaml` configuration file for YOLOv8 training, specifying:\n",
    "    - Dataset path\n",
    "    - Train and validation folder structure\n",
    "    - Class label mapping from `labels.txt`\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    project_folder : str\n",
    "        Absolute path to the root project folder. Must contain a `labels.txt` file \n",
    "        and will be used to locate or generate the `datasets/<project_name>` directory.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "        Writes a YAML file in the datasets folder for YOLO training.\n",
    "    \"\"\"\n",
    "\n",
    "    data_folder = Path(get_data_folder(project_folder))\n",
    "    project_folder = Path(project_folder)\n",
    "    project_name = project_folder.name\n",
    "\n",
    "    dataset_folder = data_folder.parent / 'datasets' / project_name\n",
    "    labels_file = data_folder / 'labels.txt'\n",
    "    yaml_path = dataset_folder / f\"{project_name}.yaml\"\n",
    "\n",
    "    # Get the annotations classes\n",
    "    annotation_classes = get_labels(labels_file)\n",
    "    \n",
    "    # Convertir les clés du dictionnaire annotation_classes en entiers\n",
    "    annotation_classes_int = {int(key): value for key, value in annotation_classes.items()}\n",
    "\n",
    "    # Formater la chaîne avec les éléments dans l'ordre souhaité\n",
    "    yaml_data = [\n",
    "        f\"path: {dataset_folder}\",\n",
    "        f\"train: 'images/train'\",\n",
    "        f\"val: 'images/val'\",\n",
    "        \"\",\n",
    "        f\"#class names\",\n",
    "        f\"names:\"]\n",
    "    \n",
    "    for class_id, label in annotation_classes_int.items():\n",
    "        yaml_data.append(f\"  {class_id}: '{label}'\")\n",
    "        \n",
    "        # TODO: Ajouter Albumentation\n",
    "\n",
    "    with open(yaml_path, 'w') as yaml_file:\n",
    "        yaml_file.write('\\n'.join(yaml_data))\n",
    "\n",
    "    print(f\"File written to {yaml_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e62ba4cd-693d-4a1a-8198-3d213c12916d",
   "metadata": {},
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4d299c9f-8939-4dac-90a4-6142fac6b396",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def yolo_training(project_folder:str, use_model:str, img_size:int, \n",
    "                  epochs:int, batch:int, workers:int, label_smoothing:float, \n",
    "                  pretrained_model:str) -> None:\n",
    "    \"\"\"\n",
    "    Trains a YOLO model using a specified dataset and configuration.\n",
    "\n",
    "    :param project_folder: \n",
    "        - Type: str\n",
    "        - Description: The absolute path to the folder named after the project.\n",
    "\n",
    "    :param use_model: \n",
    "        - Type: str\n",
    "        - Description: The YOLO model architecture to use for training (e.g., 'yolo11x.pt'). \n",
    "                       If a pre-trained model is provided, this parameter is overridden.\n",
    "\n",
    "    :param img_size: \n",
    "        - Type: int\n",
    "        - Description: The size of the input images. Larger image sizes can increase model accuracy \n",
    "                       but may also increase computational load.\n",
    "\n",
    "    :param epochs: \n",
    "        - Type: int\n",
    "        - Description: The number of epochs to train the model. More epochs allow the model to learn \n",
    "                       better but may result in overfitting if set too high.\n",
    "\n",
    "    :param batch: \n",
    "        - Type: int\n",
    "        - Description: The batch size to use during training. Larger batch sizes require more memory \n",
    "                       but can stabilize gradient updates.\n",
    "\n",
    "    :param workers: \n",
    "        - Type: int\n",
    "        - Description: The number of workers for data loading. Increasing this number can speed up data \n",
    "                       loading but may require more computational resources.\n",
    "\n",
    "    :param label_smoothing: \n",
    "        - Type: float\n",
    "        - Description: The smoothing factor applied to the labels to prevent overconfidence in predictions. \n",
    "                       Typically set between 0 and 1.\n",
    "\n",
    "    :param pretrained_model: \n",
    "        - Type: str\n",
    "        - Description: The path to a pre-trained model, if any. If provided, the function will use this model \n",
    "                       as the starting point for training. If not provided, it uses the `use_model` parameter \n",
    "                       to select the model architecture.\n",
    "\n",
    "    :return: \n",
    "        - Type: None\n",
    "        - Description: This function does not return a value. It trains the YOLO model using the provided \n",
    "                       parameters and saves the results to a specified output folder.\n",
    "\n",
    "    This function automates the YOLO training process, providing flexibility in configuration and managing results storage.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Derive additional paths and model name\n",
    "    data_folder = Path(get_data_folder(project_folder))\n",
    "    project_folder = Path(project_folder)\n",
    "    project_name = project_folder.name\n",
    "\n",
    "    dataset_folder = data_folder.parent / 'datasets' / project_name\n",
    "    yaml_file = dataset_folder / f\"{project_name}.yaml\"\n",
    "\n",
    "    date = datetime.now().strftime('%Y%m%d')\n",
    "\n",
    "    # Check if yaml_file exists\n",
    "    if not yaml_file.exists():\n",
    "        raise FileNotFoundError(f\"YAML file not found: {yaml_file}\")\n",
    "\n",
    "    # Determine which model to use\n",
    "    if pretrained_model == '':\n",
    "        model_name = f'{str(project_name)}_{date}_{Path(use_model).stem}_i{img_size}_e{epochs}_b{batch}_w{workers}'\n",
    "    else:\n",
    "        use_model = pretrained_model\n",
    "        model_name = f'{str(project_name)}_{date}_{Path(use_model).stem}_i{img_size}_e{epochs}_b{batch}_w{workers}'\n",
    "\n",
    "    # Check if the GPU is available - if not, use the CPU\n",
    "    device = which_device()\n",
    "    \n",
    "    # Load a YOLO model\n",
    "    model = YOLO(use_model).to(device)\n",
    "\n",
    "    # Train the model\n",
    "    results = model.train(\n",
    "       data = yaml_file, # path to the datasets and classes\n",
    "       imgsz = img_size, #image size\n",
    "       epochs = epochs,\n",
    "       batch = batch,\n",
    "       label_smoothing = label_smoothing,\n",
    "       workers = workers, # increases training speed, default setting is 8\n",
    "       name = model_name, # output folder\n",
    "       project = project_folder.parent / 'output' / 'runs' / 'train'\n",
    "    )\n",
    "\n",
    "    # Evaluate the model's performance on the validation set\n",
    "    val_results = model.val(\n",
    "        name = f\"{model_name}/{str(project_name)}_val\")\n",
    "    \n",
    "    print(f\"Training completed. Validation results saved to {val_results}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c0f36fa-fd39-4dc6-9229-aa6c4037aaae",
   "metadata": {},
   "source": [
    "### Resuming interrupted trainings(Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c0ad3b74-b5f5-4e59-825b-aba110229f19",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def resume_training(project_folder:str, interrupted_model_folder:str) -> None:\n",
    "    \"\"\"\n",
    "    Resumes an interrupted YOLO model training session from the last saved checkpoint.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    project_folder : str\n",
    "        Path to the root project folder (used to derive output path).\n",
    "    \n",
    "    interrupted_model_folder : str\n",
    "        Path to the folder containing the partially trained model's data. \n",
    "        This folder must include a 'weights/last.pt' file.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "        Resumes training and evaluates the model. Results are saved in the same folder.\n",
    "    \"\"\"\n",
    "\n",
    "    interrupted_model_folder = Path(interrupted_model_folder)\n",
    "    last_weight = interrupted_model_folder / 'weights' / 'last.pt'\n",
    "    \n",
    "    if not last_weight.exists():\n",
    "        raise FileNotFoundError(f\"No checkpoint found at {last_weight}\")\n",
    "    \n",
    "    model_name = interrupted_model_folder.name\n",
    "\n",
    "    project_name = Path(project_folder).name\n",
    "\n",
    "    # Check if the GPU is available - if not, use the CPU\n",
    "    device = which_device()\n",
    "    \n",
    "    # Load a model\n",
    "    model = YOLO(last_weight).to(device)  # load a partially trained model\n",
    "\n",
    "    # Resume training\n",
    "    results = model.train(resume=True)\n",
    "\n",
    "    # Evaluate the model's performance on the validation set\n",
    "    val_results = model.val(\n",
    "        name = f\"{model_name}/{str(project_name)}_val\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f0ab296-0f02-4332-87d6-8c1d7c8ed3b1",
   "metadata": {},
   "source": [
    "## Re-arrange in pristine state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8afb066e-962c-41bf-a3ba-bc8e4bb4b802",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def dispatch_data(project_folder:str, use_model:str, img_size:int, \n",
    "                  epochs:int, batch:int, workers:int, label_smoothing:float, \n",
    "                  pretrained_model:str, interrupted_model_folder:str) -> None:\n",
    "    \"\"\"\n",
    "    This function organizes and finalizes the data used for training by moving relevant files and directories \n",
    "    into the model folder. It also restores the original structure of the dataset folder by moving image and \n",
    "    annotation files back to their respective subdirectories and deletes the temporary training folder.\n",
    "\n",
    "    :return: \n",
    "        - Type: None\n",
    "        - Description: This function does not return a value. It organizes and moves files into appropriate folders, \n",
    "                       restores the original dataset structure, and deletes the temporary training folder.\n",
    "\n",
    "    This function ensures that all data and configurations used for training are stored in a dedicated model folder, \n",
    "    making it easy to track and manage different training sessions.\n",
    "    \"\"\"\n",
    "\n",
    "    data_folder = Path(get_data_folder(project_folder))\n",
    "    project_folder = Path(project_folder)\n",
    "    project_name = project_folder.name\n",
    "\n",
    "    img_folder = data_folder / 'images'\n",
    "    img_train_folder = data_folder.parent / 'datasets' / project_name / 'images' / 'train'\n",
    "    img_val_folder = data_folder.parent / 'datasets' / project_name / 'images' / 'val'\n",
    "\n",
    "    labels_folder = data_folder / 'labels'\n",
    "    labels_train_folder = data_folder.parent / 'datasets' / project_name / 'labels' / 'train'\n",
    "    labels_val_folder = data_folder.parent / 'datasets' / project_name / 'labels' / 'val'\n",
    "    \n",
    "\n",
    "    dataset_folder = data_folder.parent / 'datasets' / project_name\n",
    "    yaml_file = dataset_folder / f\"{project_name}.yaml\"\n",
    "\n",
    "\n",
    "    date = datetime.now().strftime('%Y%m%d')\n",
    "    \n",
    "    # Determine which model name to use\n",
    "    if interrupted_model_folder:\n",
    "        model_folder = Path(interrupted_model_folder)\n",
    "        model_name = model_folder.name\n",
    "    else:\n",
    "        if not pretrained_model:\n",
    "            model_name = f'{str(project_name)}_{date}_{Path(use_model).stem}_i{img_size}_e{epochs}_b{batch}_w{workers}'\n",
    "        else:\n",
    "            model_name = f'{Path(pretrained_model).name}'\n",
    "        \n",
    "        model_folder = project_folder.parent / 'output' / 'runs' / 'train' / model_name\n",
    "        \n",
    "    # Move the data used for the training session into the model folder\n",
    "    shutil.copy2(str(yaml_file), str(model_folder / f\"{project_name}.yaml\"))\n",
    "    print(f'The .yaml file has been moved into {model_folder}')\n",
    "    \n",
    "    shutil.copy2(str(data_folder / 'labels.txt'), str(model_folder / 'labels.txt'))\n",
    "    print(f'The labels.txt file has been copied in {model_folder}')\n",
    "    \n",
    "    shutil.move(str(data_folder / 'dataset_statistics'), str(model_folder))\n",
    "    print(f'The statistics folder with the training data have been moved to {model_folder}.')\n",
    "  \n",
    "    img_folder.mkdir(parents=True, exist_ok=True)\n",
    "    if img_train_folder.exists():\n",
    "        for file in img_train_folder.iterdir():\n",
    "            shutil.move(str(file), str(img_folder / file.name))\n",
    "        print(f\"Files from {img_train_folder} have been moved into {img_folder}\")\n",
    "    else:\n",
    "        print(f\"Warning: {img_train_folder} does not exist.\")\n",
    "    \n",
    "    if img_val_folder.exists():\n",
    "        for file in img_val_folder.iterdir():\n",
    "            shutil.move(str(file), str(img_folder / file.name))\n",
    "        print(f\"Files from {img_val_folder} move into {img_folder}\")\n",
    "    else:\n",
    "        print(f\"Warning: {img_val_folder} does not exist.\")\n",
    "\n",
    "    labels_folder.mkdir(parents=True, exist_ok=True)\n",
    "    if labels_train_folder.exists():\n",
    "        for file in labels_train_folder.iterdir():\n",
    "            shutil.move(str(file), str(labels_folder / file.name))\n",
    "        print(f\"Files from {labels_train_folder} move into {labels_folder}\")\n",
    "    else:\n",
    "        print(f\"Warning: {labels_train_folder} does not exist.\")\n",
    "\n",
    "    if labels_val_folder.exists():    \n",
    "        for file in labels_val_folder.iterdir():\n",
    "            shutil.move(str(file), str(labels_folder / file.name))\n",
    "        print(f\"Files from {labels_val_folder} move into {labels_folder}\")\n",
    "    else:\n",
    "        print(f\"Warning: {labels_val_folder} does not exist.\")\n",
    "\n",
    "    shutil.rmtree(str(data_folder.parent / 'datasets' / project_name))\n",
    "    print(f\"The {data_folder.parent / 'datasets' / project_name} has been deleted\")\n",
    "\n",
    "    print(f\"✅ All data successfully dispatched\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46759553-9332-4938-af01-3a8a0c179a33",
   "metadata": {},
   "source": [
    "## Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f5197c-5312-4a46-8974-f24cf2a3efc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_folder = 'ABSPATHTOTHEFOLDER' # to be changed, asbolute path to a folder with images only, without annotations.\n",
    "\n",
    "# Set to the absolute path of the pretrained model if you want to use pretrained model\n",
    "pretrained_model = 'ABSPATHTOTHEFOLDER'\n",
    "# To change if you want to use a pre-existing distribution for a training session\n",
    "preexisting_distribution = 'ABSPATHTOTHEFOLDER' # absolute path to the model folder containing the distribution to be reused\n",
    "\n",
    "# to change if you want to use pre-existing files or if you want to resume an uncompleted training session\n",
    "interrupted_model_folder = 'ABSPATHTOTHEFOLDER' # to be changed, absolute path to the model folder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20fa1ca5-16a8-4341-b643-89e6535f3d7c",
   "metadata": {},
   "source": [
    "### Clean, increase and split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e7ad5c3b-9e17-42d4-8313-b7e69e2c1056",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean the file txt if needed\n",
    "clean_comma(project_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13381455-a63d-48db-bb52-8ca57c9296f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%prun\n",
    "# Use the perspective transformation to extend the dataset\n",
    "generate_transformed_data(project_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c4e7bf7-9f5f-4745-a764-4d7999c26969",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate data distribution file for train/val sets\n",
    "create_training_dataset(project_folder, pretrained_model, preexisting_distribution=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8faef8d5-8d19-4d9a-9663-b3006efd81c8",
   "metadata": {},
   "source": [
    "### Start a training session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f26d4889-bda8-4246-9ffe-433fca7f097e",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_model = 'yolo11n.pt' # to be changed as needed, by default use 'yolov11x.pt'\n",
    "img_size = 640 # to be changed as needed, by default use 640\n",
    "epochs = 10 # to be changed as needed\n",
    "batch = -1 # to be changed as needed, by default use 8 or or -1 for AutoBatch\n",
    "workers = 8 # to be changed as needed, by default 24, or 8 (https://docs.ultralytics.com/modes/train/#train-settings)\n",
    "label_smoothing = 0.1 # to be changed as needed,by default 0. Can improve generalization\n",
    "dropout = 0.1 # Elimine aléatoirement 10% connaissance à chaque époque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd918a0-d728-4bf6-bb3f-4d3d9cbede6f",
   "metadata": {
    "editable": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Start a training session\n",
    "yolo_training(project_folder, use_model, img_size, epochs, batch, workers, label_smoothing, pretrained_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e99f24af-f762-4ec0-a19d-36f4f8abbe54",
   "metadata": {},
   "source": [
    "### Resume an uncompleted training session (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8709f993-f1ba-4f00-a454-53ca4ebb6bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resume an interrupted training\n",
    "#resume_training(project_folder, interrupted_model_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74460189-6de3-452a-8713-ae5952dabf0a",
   "metadata": {},
   "source": [
    "### Dispatch the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aae5b7b-d9ce-408c-b677-c8d2496ff2ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move the .txt files describing the distribution of images/labels in train and val of the training data into the model folder and replace the image/label data themself in their original folders\n",
    "dispatch_data(project_folder, use_model, img_size, \n",
    "                  epochs, batch, workers, label_smoothing, \n",
    "                  pretrained_model, interrupted_model_folder)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tiamat_env",
   "language": "python",
   "name": "tiamat_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
