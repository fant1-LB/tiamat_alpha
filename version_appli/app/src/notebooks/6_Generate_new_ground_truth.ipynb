{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20230cd5-51dc-48fb-b156-d67fc7eed78c",
   "metadata": {},
   "source": [
    "# Using and handling corrected files\n",
    "\n",
    "## Generating ground truth\n",
    "\n",
    "This notebook lets you use the corrected annotation data generated in previous notebooks. For the code to work, you must have run an inference and corrected the annotations produced.\n",
    "\n",
    "This step concludes a training, prediction and correction session. The data in the correction files have a ground truth value and can be used to launch a new training session.\n",
    "\n",
    "**Warning**\n",
    "\n",
    "The code is efficient only if the project structure is correct. If the tree structure differs from the one shown below, errors will occur.\n",
    "\n",
    "To ensure that applying the code is as straightforward as possible, let's review the structure of the working folder and its naming constraints. This is not the whole structure, although here are the extracts that will have an influence on the code's effectiveness.\n",
    "\n",
    "```\n",
    "working_folder\n",
    "├─── partage\n",
    "│    ├─── project_name\n",
    "│    │    ├─── in\n",
    "│    │    │    ├─── non_annotated_images\n",
    "│    │    │    └─── annotated_images\n",
    "│    │    └─── out\n",
    "│    │         ├─── annotations\n",
    "│    │         └─── corrections\n",
    "└─── output\n",
    "     └─── runs\n",
    "          ├─── train\n",
    "          │    └─── model_folder\n",
    "          └─── predict\n",
    "               └─── result_folder\n",
    "                    └─── correctedLabels\n",
    "```\n",
    "\n",
    "The only freely nameable folder is '**project_name**'. The name of the '**model_folder**' folder has already been named automatically if you have run the previous notebooks.\n",
    "\n",
    "The same applies to the name of the '**result_folder**' folder. It is generated from the names of the '**project_name**' and '**model_folder**' folders, separated by an underscore. If you rename either folder, make sure you always follow this naming scheme. For instance:\n",
    "\n",
    "```\n",
    "project_name = projet01\n",
    "model_folder = model01\n",
    "\n",
    "result_folder = projet01_model01\n",
    "```\n",
    "\n",
    "This notebook will essentially act on the '**partage**' folder. It is however essential to access the '**model_folder**' in order to retrieve the '**label.txt**' file to then process the corrected annotations.\n",
    "\n",
    "The same applies to the '**result_folder**' folder, as its subfolder '**correctedLabels**' shall host the .txt files resulting from the processing.\n",
    "\n",
    "Consequently, make sure you dispose of the following folders and/or files:\n",
    "- A folder containing the unannotated images ('**partage/project_name/in/non_annotated_images**');\n",
    "- A folder containing the '**labels.txt**' file with annotation labels ('**output/runs/train/model_folder**');\n",
    "- A folder containing the corrected JSON files ('**partage/project_name/out/corrections**').\n",
    "\n",
    "**Notice concerning use** \n",
    "\n",
    "Any use, even partial, of the content of this notebook must be accompanied by an appropriate citation.\n",
    "\n",
    "&copy; 2024 Marion Charpier "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6a1d1f6-c2a0-4360-8721-0e9f980656f4",
   "metadata": {},
   "source": [
    "## Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bac537aa-8d9d-457c-bfca-fba962915467",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "\n",
    "import sys\n",
    "sys.path.append(str(Path.cwd().parent / 'modules'))\n",
    "\n",
    "from folders_path import *\n",
    "from manipulate_files import open_json_file, change_id\n",
    "from transform_coordinates_functions import from_ls_to_yolo\n",
    "from class_names_functions import get_labels, get_class_code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1444738d-68a3-45b9-a3f4-11a47f8882f2",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6edf265d-590e-4448-bafd-d38bc55491cb",
   "metadata": {},
   "source": [
    "### Create a new dataset with the correction files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7eebdb0-4b59-46b1-aeec-e1d5e1287879",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_new_ground_truth(project_folder:str, yolo_model_folder:str, wanna_create:bool) -> None:\n",
    "    \"\"\"\n",
    "    Update an existing YOLO dataset with corrected labels, evaluation images, and an updated class list.\n",
    "\n",
    "    This function integrates annotation corrections produced during evaluation into the main dataset.\n",
    "    Instead of creating a new dataset folder, it updates the existing one in place by:\n",
    "      - Copying corrected label files from the results folder into the dataset `labels/` directory\n",
    "        (overwriting any files with the same name).\n",
    "      - Copying evaluation images into the dataset `images/` directory (adding new files as needed).\n",
    "      - Replacing the dataset `labels.txt` file with the one generated during evaluation,\n",
    "        ensuring that new or updated classes are included.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    project_folder : str\n",
    "        Path to the main project folder. Must contain `image_inputs/eval_images` with\n",
    "        evaluation images to be integrated into the dataset.\n",
    "    yolo_model_folder : str\n",
    "        Path to the YOLO model folder. Used to locate the evaluation results\n",
    "        (`labels.txt` and `correctedLabels/`).\n",
    "    wanna_create : bool\n",
    "        If False, the function exits without performing any action.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "        This function performs file operations in place. It does not return a value.\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    - Both `labels/` and `images/` subfolders are created inside the dataset folder if they do not exist.\n",
    "    - Files are copied with overwrite: existing label files or images with the same name will be replaced.\n",
    "    - `labels.txt` is atomically replaced to avoid corruption.\n",
    "    - If the corrections folder or evaluation images folder are missing, the function exits early.\n",
    "    \"\"\"\n",
    "    \n",
    "    if not wanna_create:\n",
    "        print('No new dataset generated')\n",
    "        return\n",
    "\n",
    "    # Recompose paths\n",
    "    results_folder = get_results_folder(project_folder, yolo_model_folder)\n",
    "    eval_folder = Path(get_img_folder_inference(project_folder))\n",
    "    data_folder = get_data_folder(project_folder)\n",
    "    labels_folder = Path(data_folder) / 'labels'\n",
    "    img_folder = Path(data_folder) / 'images'\n",
    "    labels_file_src = Path(results_folder) / 'labels.txt'\n",
    "    labels_file_dst = Path(data_folder) / 'labels.txt'\n",
    "    corrections_folder = Path(results_folder) / 'correctedLabels'\n",
    "\n",
    "    # If not exist, create the destination folders\n",
    "    labels_folder.mkdir(parents=True, exist_ok=True)\n",
    "    img_folder.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    if not corrections_folder.exists() or not corrections_folder.is_dir():\n",
    "        print(f\"[WARN] Corrections folder not found: {corrections_folder}\")\n",
    "        return\n",
    "    \n",
    "    if not eval_folder.exists() or not eval_folder.is_dir():\n",
    "        print(f\"[WARN] Eval images folder not found: {eval_folder}\")\n",
    "        return\n",
    "    \n",
    "    # Copy labels to the new dataset\n",
    "    copied_labels = 0\n",
    "    for file in corrections_folder.iterdir():\n",
    "        if file.is_file():\n",
    "            shutil.copy2(str(file), str(labels_folder / file.name))\n",
    "            copied_labels +=1\n",
    "    print(f\"[OK] {copied_labels} corrected label file(s) copied to {labels_folder}\")\n",
    "    \n",
    "    # Copy images to the new dataset\n",
    "    copied_imgs = 0\n",
    "    img_exts = {'.jpg', '.jpeg', '.png', '.tif', '.tiff'}\n",
    "    for file in eval_folder.iterdir():\n",
    "        if file.is_file() and file.suffix.lower() in img_exts:\n",
    "            shutil.copy2(str(file), str(img_folder/ file.name))\n",
    "            copied_imgs +=1\n",
    "    print(f\"[OK] {copied_imgs} image(s) copied to {img_folder}\")\n",
    "    \n",
    "    # AJOUTER ICI LE FILTRE POUR LES IMAGES DEFORMEES\n",
    "\n",
    "    # Copy the labels file\n",
    "    if labels_file_src.exists() and labels_file_src.is_file():\n",
    "        shutil.copy2(str(labels_file_src), str(labels_file_dst))\n",
    "        print(f\"Labels file copied to: {str(labels_file_dst)}\")\n",
    "    else:\n",
    "        print(f\"[WARN] labels.txt not found in results: {labels_file_src}\")\n",
    "        \n",
    "    print(\"[DONE] Dataset updated in place.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01ef10aa-bb07-4ef6-9f4b-63e5594339f9",
   "metadata": {},
   "source": [
    "### Move correction files and annotated images to the proper folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f57ec816-f9bf-44a8-bb2a-ec940e2443e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def move_correction_files_and_images(project_folder:str) -> None:\n",
    "    \"\"\"\n",
    "    Move evaluation images and correction JSON files into their designated folders within the project structure.\n",
    "\n",
    "    This function organizes data after evaluation by:\n",
    "      - Moving evaluation images from `image_inputs/eval_images/` into `image_inputs/ground_truth_images/`.\n",
    "      - Moving correction JSON files from `annotations/prediction_corrections/` into `annotations/ground_truth/`.\n",
    "      - Ensuring that annotation filenames are unique (incrementing the filename number if necessary).\n",
    "      - Updating the \"id\" field inside each JSON annotation to match its new filename.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    project_folder : str\n",
    "        Path to the main project folder containing the `image_inputs/` and `annotations/` subdirectories.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "        The function performs file moves and modifications in place. It does not return a value.\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    - Existing images or annotation files with the same name are renamed to ensure uniqueness.\n",
    "    - Hidden files (starting with `.`) are ignored when processing annotations.\n",
    "    - The `change_id()` function must exist in the codebase and is expected to update the \"id\" field\n",
    "      of each moved JSON annotation file.\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    # Recompose paths\n",
    "    ground_truth_img_folder = Path(get_img_folder_training(project_folder))\n",
    "    eval_folder = Path(get_img_folder_inference(project_folder))\n",
    "    ground_truth_folder = Path(get_ground_truth_folder_training(project_folder))\n",
    "    pred_cors_folder = Path(get_corrections_folder_inference(project_folder))\n",
    "    \n",
    "\n",
    "    # Move .jpg images to the annotated images folder\n",
    "    img_exts = {'.jpg', '.jpeg', '.png', '.tif', '.tiff'}\n",
    "    for file in eval_folder.iterdir():\n",
    "        if file.is_file() and file.suffix.lower() in img_exts:\n",
    "            shutil.move(str(file), str(ground_truth_img_folder / file.name))\n",
    "    print(f\"Images moved from {eval_folder} to {ground_truth_img_folder}\")\n",
    "\n",
    "    # Move correction files to the annotations folder\n",
    "    for file in pred_cors_folder.iterdir():\n",
    "        if file.is_file() and not file.name.startswith('.'):\n",
    "            # Ensure unique file name\n",
    "            new_annotation = ground_truth_folder / file\n",
    "            annotation_number = int(Path(file).stem)\n",
    "\n",
    "            while new_annotation.exists():\n",
    "                annotation_number += 1\n",
    "                new_annotation = ground_truth_folder / str(annotation_number)\n",
    "                \n",
    "            shutil.move(str(pred_cors_folder /file), str(new_annotation))\n",
    "\n",
    "            # Changes the 'id' field in the JSON file to the basename of the file path\n",
    "            change_id(new_annotation)\n",
    "            \n",
    "    print(f\"Annotations files corrected and moved to {str(pred_cors_folder)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24665c1c-8a0e-4ce9-b128-a17e6e892c17",
   "metadata": {},
   "source": [
    "### Add the image data to the pre-existing CSV (or create one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da8b3171-551e-4fb3-9d83-685a445da03c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_csv_data(project_folder:str, yolo_model_folder:str) -> None:\n",
    "    \"\"\"\n",
    "    Consolidate image metadata CSV files for a YOLO project.\n",
    "\n",
    "    This function ensures that all relevant image metadata (filename, folder, dimensions, format, etc.)\n",
    "    is stored in a single CSV file inside the `ground_truth_images` folder. It handles three cases:\n",
    "\n",
    "      1. If no CSV files exist, it scans all images in `ground_truth_images/` and generates a new CSV file.\n",
    "      2. If only the annotated CSV exists, it scans `ground_truth_images/` and appends any missing images\n",
    "         not already listed in the annotated CSV.\n",
    "      3. If both annotated and non-annotated CSVs exist, it merges them intelligently, updating folder paths\n",
    "         from `eval_images/` to `ground_truth_images/` and removing duplicates.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    project_folder : str\n",
    "        Path to the main project folder. Must contain:\n",
    "        - `image_inputs/ground_truth_images/` for annotated images.\n",
    "        - `image_inputs/eval_images/` for evaluation images and their CSV, if it exists.\n",
    "    yolo_model_folder : str\n",
    "        Path to the YOLO model folder (currently not directly used, but included\n",
    "        for compatibility with the rest of the pipeline).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "        This function updates or creates the CSV file `*_data.csv` inside `ground_truth_images/`.\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    - The consolidated CSV uses `;` as a separator.\n",
    "    - Duplicate entries (same `Image_name`) are avoided.\n",
    "    - Image metadata includes: name, folder path, absolute path, format, width, height, and pixel count.\n",
    "    - Non-annotated CSVs (from `eval_images`) are migrated and harmonized to point to `ground_truth_images`.\n",
    "    \"\"\"\n",
    "\n",
    "    # Recompose paths\n",
    "    project_name = Path(project_folder).name\n",
    "    ground_truth_img_folder = Path(get_img_folder_training(project_folder))\n",
    "    eval_folder = Path(get_img_folder_inference(project_folder))\n",
    "    \n",
    "    non_annotated_csv = eval_folder / f'{project_name}.csv'\n",
    "    annotated_csv = ground_truth_img_folder / f\"{project_name}_data.csv\"\n",
    "\n",
    "    img_exts = {'.jpg', '.jpeg', '.png', '.tif', '.tiff'}\n",
    "\n",
    "\n",
    "    # 2. Existence checks\n",
    "    exists_non = non_annotated_csv.exists()\n",
    "    exists_ann = annotated_csv.exists()\n",
    "    if not exists_non and not exists_ann:\n",
    "        print(\"No CSV found.\")\n",
    "        \n",
    "        data = []\n",
    "        images = [\n",
    "            img for img in ground_truth_img_folder.iterdir()\n",
    "            if img.is_file() and img.suffix.lower() in img_exts\n",
    "        ]\n",
    "\n",
    "        for file in images:\n",
    "            img_name = file.stem\n",
    "\n",
    "            with Image.open(file) as img:\n",
    "                absolute_path = img.filename\n",
    "                format = img.format\n",
    "                w, h  = img.size\n",
    "                img_size = w * h\n",
    "\n",
    "            img_data = {\n",
    "                'Image_name'   : str(img_name),\n",
    "                'Folder'       : str(ground_truth_img_folder),\n",
    "                'Absolute_path': absolute_path,\n",
    "                'Format'       : format,\n",
    "                'Width'        : w,\n",
    "                'Height'       : h,\n",
    "                'Image_size'   : img_size\n",
    "            }\n",
    "\n",
    "            data.append(img_data)\n",
    "\n",
    "        # Create a DataFrame from the image data list\n",
    "        df = pd.DataFrame(data)\n",
    "\n",
    "        # Save DataFrame to a CSV file\n",
    "        csv_filepath = annotated_csv\n",
    "        df.to_csv(csv_filepath, sep=';', index=False)\n",
    "\n",
    "        print(f\"Image data saved to {csv_filepath}\")\n",
    "        return\n",
    "\n",
    "    # 3. Case: only the annotated CSV exists -> add the non-annotated images\n",
    "    if exists_ann and not exists_non:\n",
    "        print(\"Adding non-annotated images to the existing annotated CSV…\")\n",
    "        # Load the existing CSV to get already included names\n",
    "        df_annot = pd.read_csv(annotated_csv, sep=';')\n",
    "        existing_names = set(df_annot['Image_name'])\n",
    "\n",
    "        # Build the list of images to consider\n",
    "        images = [\n",
    "            img for img in ground_truth_img_folder.iterdir()\n",
    "            if img.is_file() and img.suffix.lower() in img_exts\n",
    "        ]\n",
    "\n",
    "        new_rows = []\n",
    "        for img_path in images:\n",
    "            img_name = img_path.stem\n",
    "            # If this name is already in the annotated CSV, skip it\n",
    "            if img_name in existing_names:\n",
    "                continue\n",
    "\n",
    "            with Image.open(img_path) as img:\n",
    "                absolute_path = img.filename\n",
    "                w, h  = img.size\n",
    "                img_size = w * h\n",
    "\n",
    "            new_rows.append({\n",
    "                'Image_name'   : str(img_name),\n",
    "                'Folder'       : str(ground_truth_img_folder),\n",
    "                'Absolute_path': absolute_path,\n",
    "                'Format'       : img.format,\n",
    "                'Width'        : w,\n",
    "                'Height'       : h,\n",
    "                'Image_size'   : w * h\n",
    "            })\n",
    "\n",
    "        if not new_rows:\n",
    "            print(\"No new images to add.\")\n",
    "            return\n",
    "\n",
    "        df_new = pd.DataFrame(new_rows)\n",
    "        \n",
    "        # Concatenate only the new rows\n",
    "        merged = pd.concat([df_annot, df_new], ignore_index=True)\n",
    "        merged.to_csv(annotated_csv, sep=';', index=False)\n",
    "        print(f\"{len(df_new)} image(s) added to {annotated_csv}\")\n",
    "\n",
    "        return\n",
    "\n",
    "    # 4. Case: both CSVs exist -> intelligent merge\n",
    "    df_annot = pd.read_csv(annotated_csv, sep=';') if exists_ann else pd.DataFrame()\n",
    "    df_non   = pd.read_csv(non_annotated_csv, sep=';') if exists_non else pd.DataFrame()\n",
    "    \n",
    "    # Update paths from eval_images → ground_truth_images\n",
    "    if not df_non.empty:\n",
    "        df_non['Folder'] = df_non['Folder'].str.replace('eval_images', 'ground_truth_images')\n",
    "        df_non['Absolute_path'] = df_non['Absolute_path'].str.replace(\n",
    "            'eval_images', 'ground_truth_images'\n",
    "        )\n",
    "\n",
    "    # Remove from df_non the images already present in df_annot\n",
    "    existing_names    = set(df_annot['Image_name'])\n",
    "    df_non_filtered   = df_non.query(\"Image_name not in @existing_names\")\n",
    "\n",
    "    if df_non_filtered.empty:\n",
    "        print(\"No additional non-annotated images to merge.\")\n",
    "    else:\n",
    "        merged = pd.concat([df_annot, df_non_filtered], ignore_index=True)\n",
    "        merged.to_csv(annotated_csv, sep=';', index=False)\n",
    "        print(f\"{len(df_non_filtered)} image(s) merged into {annotated_csv}\")\n",
    "        return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d248cb6b-f390-4fd8-afae-5043d49182b7",
   "metadata": {},
   "source": [
    "## Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be12d737-c5b4-4976-bec2-b87a2afe5c8f",
   "metadata": {},
   "source": [
    "### Enter absolute paths for variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3287babd-d323-4aa9-a70b-b5c4b74cd709",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_folder = 'ABSPATHTOTHEFOLDER' # To be changed. Absolute path to the folder named after your project.\n",
    "yolo_model_folder = 'ABSPATHTOTHEMODELFOLDER' # To be changed. Asbolute path to the folder with the training data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20b7200d-d944-4b7a-8641-082932625fa2",
   "metadata": {},
   "source": [
    "### Create the next dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d484ec66-7f9a-4f27-b529-ae9bcc84e4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_new_ground_truth(project_folder, yolo_model_folder, wanna_create=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4fd51ba-6b30-42fa-9994-1ea2900b16a1",
   "metadata": {},
   "source": [
    "### Move images and JSON files to the proper folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faaca945-6a36-4caa-a014-fd6a25bc7e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "move_correction_files_and_images(project_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eb55365-3ebb-497c-b622-643363e8dbcb",
   "metadata": {},
   "source": [
    "### Add the image data to the pre-existing CSV (or create one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70473ccc-a0a3-4f7f-ada6-fbc6481724f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_csv_data(project_folder, yolo_model_folder)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tiamat_env",
   "language": "python",
   "name": "tiamat_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
