<p align="center">
  <img src="docs/assets/Dingir.png" alt="TiamaT Logo" width="100"/>
</p>

# ğŸ‰ TiamaT â€“ Toolkit for Integrated Annotation and Machine-learning Assisted Training

**TiamaT** is a complete, modular pipeline that helps transform raw, unstructured images into fully annotated, machine learningâ€“ready datasets.

Designed for flexibility and reusability, it supports every step of the computer vision training workflow:
- ğŸ“Œ Manual annotation with [Label Studio](https://labelstud.io/)
- ğŸ”§ Dataset formatting and transformation
- ğŸ§  Model training and inference using YOLO
- âœ… Evaluation and correction through human-in-the-loop cycles

Originally built for historical document analysis, TiamaT fits any project where annotations are built incrementally or interactively.

> The name is a nod to [**Tiamat**](https://en.wikipedia.org/wiki/Tiamat), the Mesopotamian goddess of the ocean and chaos â€” an appropriate symbol for turning raw data into structured knowledge.

---

## Table of Contents

- [ğŸŒ Workflow Overview](#-workflow-overview)
  - [ğŸ’« Execution Modes (Notebook & Script)](#-execution-modes-notebook--script)
  - [ğŸ§¿ Pipeline Steps Overview](#ï¸-pipeline-steps-overview)
  - [ğŸ§± Project Folder Structure](#-project-folder-structure)
- [ğŸš€ Running TiamaT](#-running-tiamat)
  - [ğŸ¦â€ğŸ”¥ Iterative Workflow](#-iterative-workflow)
  - [ğŸŒˆ Shared Configuration Variables](#-shared-configuration-variables)
- [ğŸ§© Installation](#ï¸-installation)
  - [ğŸ‘¾ Requirements](#-requirements) 
  - [ğŸ–Œï¸ Label Studio Environment](#-label-studio-environment)
    - [ğŸ“¦ Using Conda](#-using-conda)
    - [ğŸ Using a Python virtual environment](#-using-a-python-virtual-environment)
  - [ğŸ² Tiamat Environment](#-tiamat-environment)
    -  [ğŸ“¦ Using Conda](#-using-conda-1)
    - [ğŸ Using a Python virtual environment](#-using-a-python-virtual-environment-1)
- [ğŸ“œ License & Attribution](#-license--attribution)

---

## ğŸŒ Workflow Overview

The TiamaT pipeline covers the full annotation-to-training lifecycle.
It is organized as a **modular sequence of stages**, which can be executed in two different modes depending on your needs:


### ğŸ’« Execution Modes (Notebook & Script)

You can use TiamaT either as:

- ğŸ““ **Interactive notebooks** â€“ ideal for exploration, development, or adjusting specific parameters step by step.
- âš™ï¸ **Command-line scripts** â€“ ideal for automation, production, or batch execution.

Each stage of the pipeline exists in both formats. The scripts are located in `src/scripts/` and replicate the logic of the Jupyter notebooks in `src/notebooks/`.

> You can mix both modes depending on your workflow â€” for instance, prototype in notebook, then automate with scripts.

---

### ğŸ§¿ Pipeline Steps Overview

> [!NOTE]
> For a detailed description of each stage (inputs, outputs, scripts, tips), see [docs/pipeline_overview.md](docs/pipeline_overview.md).



| Stage | Description | Notebook | Script |
|-------|-------------|----------|--------|
| **0** | Launch Label Studio (optional) | `0_Launching_LS.ipynb` | *Use `label-studio` CLI* |
| **1** | Extract annotated training data | `1_Get_training_data.ipynb` | `extract_training_data.py` |
| **2** | Compute dataset statistics | `2_Statistics_for_training_data.ipynb` | `analyze_dataset.py` |
| **3** | Prepare data and train model | `3_Data_preparation_and_training.ipynb` | `train_model.py` |
| **4** | Predict on new images | `4_Predicting_and_checking_YOLO_results.ipynb` | `predict.py` |
| **5** | Evaluate model & review corrections | `5_Model_evaluation.ipynb` | `evaluate_model.py` |
| **6** | Generate updated ground truth | `6_Generate_new_ground_truth.ipynb` | `generate_ground_truth.py` |

> ğŸ“ Notebooks are recommended for first-time users and experimentation.
>
> ğŸ–¥ï¸ Scripts are better suited for iterative workflows and large-scale runs.

---

### ğŸ§± Project Folder Structure

To ensure smooth execution, the TiamaT pipeline expects a specific folder organization.
This structure separates raw inputs, manual annotations, training datasets, and model outputs in a modular and reproducible way.

```
TiamaT/
â”œâ”€â”€ data/                         # Final YOLO-formatted training datasets (images, labels, labels.txt)
â”œâ”€â”€ project/                      # Raw images and annotations (excluded from Git except structure)
â”‚   â”œâ”€â”€ image_inputs/             # Source images used in the pipeline
â”‚   â”‚   â”œâ”€â”€ ground_truth_images/       # Manually annotated images used for training
â”‚   â”‚   â””â”€â”€ eval_images/               # Images used for inference and manual correction
â”‚   â”œâ”€â”€ annotations/             # Annotations exported or corrected via Label Studio
â”‚   â”‚   â”œâ”€â”€ ground_truth/              # Ground truth annotations manually created in LS
â”‚   â”‚   â””â”€â”€ prediction_corrections/    # Corrections made after model predictions
â”œâ”€â”€ output/                       # Model training and prediction results
â”‚   â””â”€â”€ runs/
â”‚       â”œâ”€â”€ train/                     # YOLO training runs (auto-generated folders: exp1, exp2, ...)
â”‚       â””â”€â”€ predict/                   # Inference outputs (e.g., predicted labels)
â”œâ”€â”€ src/                          # Core source code
â”‚   â”œâ”€â”€ notebooks/                   # Step-by-step Jupyter notebooks for the full pipeline
â”‚   â”œâ”€â”€ scripts/                     # Python scripts for CLI-based execution
â”‚   â”œâ”€â”€ modules/                     # Reusable Python modules (transforms, utils, etc.)
â”‚   â””â”€â”€ config.py                    # Shared configuration and path definitions
â”œâ”€â”€ requirements/                 # Installation requirements (pip or conda)
â”‚   â”œâ”€â”€ tiamat.txt                   # Main pipeline dependencies (YOLO, OpenCV, etc.)
â”‚   â””â”€â”€ label_studio.txt             # Label Studio annotation environment
â”œâ”€â”€ .env.example                 # Template for custom environment variables
â””â”€â”€ README.md                    # Main project documentation

```

â­ï¸ All notebooks and scripts rely on this layout to locate and process data automatically.

> [!WARNING]
> Only `project_name` can be freely renamed â€” all other folder names must be preserved for the code to function correctly.


---

## ğŸš€ Running TiamaT

Once your environments are set up and the project structure is ready, you can execute the pipeline either via Jupyter notebooks or Python scripts (see [Workflow Overview](#-workflow-overview) for the full step mapping).

### ğŸ¦â€ğŸ”¥ Iterative Workflow

TiamaT is built around a human-in-the-loop workflow.
The model is not evaluated on a classic "test set", but rather through manual correction of its predictions. This makes the pipeline especially useful when no gold-standard ground truth exists upfront.

```text
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚ 0. Launch Label Studio     â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                  
                      â–¼                 
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           
        â”‚ 1. Extract Training Data   â”‚           
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           
                      â–¼                          
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             
        â”‚ 2. Dataset Statistics      â”‚ â—„â”€â”€â”€â”€â”€â”
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
                      â–¼                      â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
        â”‚ 3. Train YOLO Model        â”‚       â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
                      â–¼                      â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
        â”‚ 4. Predict with Model      â”‚       â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
                      â–¼                      â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
        â”‚ 5. Review + Correction     â”‚       â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
                      â–¼                      â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
        â”‚6. Generate New Ground Truthâ”‚â”€â”€â”€â”€â”€â”€â”€â”˜
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

           â¤· Loop back to step 3 to retrain
```



You can repeat steps 3 to 6 as many times as needed to improve the modelâ€™s performance, especially when working with complex or evolving datasets.

ğŸ“Œ You may skip any step if you're starting from partially prepared data or existing corrections.

---

### ğŸŒˆ Shared Configuration Variables

Some key variables are shared across both notebooks and scripts.  
They define core paths, session parameters, and model references, and are typically loaded from a `.env` file using the [`python-dotenv`](https://pypi.org/project/python-dotenv/) package.

| Variable | Description |
|----------|-------------|
| `project_folder` | Absolute path to the folder containing your dataset. By default, this is `project/`, but it can be renamed freely. |
| `model_folder` | Path to the YOLOv8 model directory used for inference or evaluation (e.g., `output/runs/train/model_name/`) |
| `pretrained_model` | Path to a pre-trained YOLOv8 model (e.g., `best.pt`) if you want to fine-tune instead of training from scratch |

ğŸ“Œ `project_folder` is the central directory used throughout the pipeline.  
Make sure the structure inside follows the [Project Folder Structure](#-project-folder-structure) for the notebooks to run correctly.

These variables are typically defined in your `.env` file and automatically loaded into both notebooks and scripts at runtime.

---

## ğŸ§© Installation

TiamaT uses **two separate environments**:

- ğŸ–Œï¸ One for annotation and project setup using [Label Studio](https://labelstud.io/)
- ğŸ² One for model training, inference, and evaluation using [YOLO](https://github.com/ultralytics/ultralytics)

You can install both environments using either **Conda** or **Python virtual environments (venv)**.

---

### ğŸ‘¾ Requirements

Before installing, make sure you have:

- Python **3.10+**
- Either `conda` or `venv` (choose your preferred environment manager)
- Jupyter Notebook or JupyterLab (only needed for notebook users)
- Internet access to fetch packages

ğŸ“¦ Dependencies are listed in the `requirements/` folder:
- `label_studio.txt` or `label_studio_environment.yml`
- `tiamat.txt` or `tiamat_environment.yml`

> âš ï¸ **PyTorch and Torchvision** are installed automatically as dependencies of [Ultralytics](https://github.com/ultralytics/ultralytics).  
> If you encounter issues with GPU support or CUDA versions, refer to [PyTorch installation guide](https://pytorch.org/get-started/locally) to reinstall a suitable version.

---

### ğŸ–Œï¸ Setting up the Label Studio Environment

#### ğŸ“¦ Using Conda

```bash
conda create --name label-studio
conda activate label-studio

# Only required for Label Studio 1.7.2
conda install psycopg2

pip install label-studio
```

#### ğŸ Using a Python virtual environment

```bash
python3 -m venv label-studio_env
source label-studio_env/bin/activate

pip install --upgrade pip
pip install label-studio
```

> [!NOTE]
> For more information about installing Label Studio, see the official documentation:
> - [Install with Anaconda](https://labelstud.io/guide/install.html#Install-with-Anaconda)
> - [Install using pip](https://labelstud.io/guide/install.html#Install-using-pip)

---

### ğŸ² Setting up the TiamaT Environment (YOLO)
#### ğŸ“¦ Using Conda

```bash
conda env create -f requirements/tiamat_environment.yml
conda activate tiamat_env

# âš ï¸ Install PyTorch manually according to your system:
# https://pytorch.org/get-started/locally
```

#### ğŸ Using a Python virtual environment

```bash
python3 -m venv tiamat_env
source tiamat_env/bin/activate

pip install --upgrade pip
pip install -r requirements/tiamat.txt

# âš ï¸ Then install PyTorch manually from:
# https://pytorch.org/get-started/locally
```

---

### ğŸ““ (Optional) Jupyter Kernel Registration

If you plan to use Jupyter notebooks, you may register each environment as a kernel:

```bash
# Install Jupyter-compatible kernel support
pip install ipython ipykernel
python -m ipykernel install --user --name=<env_name>

```
> ![WARNING]
> Replace <env_name> with `label-studio_env` or `tiamat_env` accordingly.

This step is **not required** if you're only using the scripts in `src/scripts/`.

---

You're now ready to run the pipeline â€” either through interactive notebooks or command-line scripts.

---

ğŸŒŸ Whether you're working on historical archives, custom datasets, or iterative model refinement, TiamaT is designed to adapt to your workflow.

---

## ğŸ“œ License & Attribution

Any use, even partial, of the content in this repository must be accompanied by proper citation.

**Made with â¤ï¸ by [Marion Charpier](https://github.com/Chaouabti/) & [Fantin Le Ber](https://github.com/fant1-LB)**  
Â© 2023â€“2025 â€¢ Project **TiamaT**

---

ğŸ™Œ Want to contribute? See [docs/CONTRIBUTING.md](docs/CONTRIBUTING.md).